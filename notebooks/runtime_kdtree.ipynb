{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T12:14:21.606785400Z",
     "start_time": "2023-10-02T12:14:21.587804200Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import timeit\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from dataset.dataset import Dataset\n",
    "from models.neural_net import NeuralNet\n",
    "from models.sampled_net import SampledNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def wrapper(func, *args, **kwargs):\n",
    "    def wrapped():\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapped\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:14:21.606785400Z",
     "start_time": "2023-10-02T12:14:21.603430600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T12:14:21.627585900Z",
     "start_time": "2023-10-02T12:14:21.606785400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<dataset.dataset.Dataset at 0x1d8bb922090>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "xd = 2  # Input space dimensions\n",
    "yd = 4  # Output dimension\n",
    "num_samples = 1500  # Number of data points\n",
    "layer_width = 100\n",
    "epochs = 300\n",
    "\n",
    "dataset = Dataset()\n",
    "dataset.create_dataset_laplacian_of_gaussian(num_samples)\n",
    "dataset.scale(preprocessing.MinMaxScaler(feature_range=(-2, 2)))\n",
    "dataset.split_train_test(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train network with Adam"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T12:14:48.644655200Z",
     "start_time": "2023-10-02T12:14:21.627585900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "38/38 [==============================] - 1s 5ms/step - loss: 0.7939 - val_loss: 1.0335\n",
      "Epoch 2/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5739 - val_loss: 0.9761\n",
      "Epoch 3/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5502 - val_loss: 0.9477\n",
      "Epoch 4/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5379 - val_loss: 0.9199\n",
      "Epoch 5/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 0.9008\n",
      "Epoch 6/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5185 - val_loss: 0.8833\n",
      "Epoch 7/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5098 - val_loss: 0.8643\n",
      "Epoch 8/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5020 - val_loss: 0.8511\n",
      "Epoch 9/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4978 - val_loss: 0.8419\n",
      "Epoch 10/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.8212\n",
      "Epoch 11/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4889 - val_loss: 0.8096\n",
      "Epoch 12/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 0.7976\n",
      "Epoch 13/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.7904\n",
      "Epoch 14/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.7834\n",
      "Epoch 15/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4743 - val_loss: 0.7733\n",
      "Epoch 16/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4713 - val_loss: 0.7707\n",
      "Epoch 17/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4697 - val_loss: 0.7602\n",
      "Epoch 18/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.7553\n",
      "Epoch 19/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4643 - val_loss: 0.7482\n",
      "Epoch 20/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.7452\n",
      "Epoch 21/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4636 - val_loss: 0.7431\n",
      "Epoch 22/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4595 - val_loss: 0.7344\n",
      "Epoch 23/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4568 - val_loss: 0.7363\n",
      "Epoch 24/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4585 - val_loss: 0.7234\n",
      "Epoch 25/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.7251\n",
      "Epoch 26/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4514 - val_loss: 0.7199\n",
      "Epoch 27/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4509 - val_loss: 0.7253\n",
      "Epoch 28/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4495 - val_loss: 0.7132\n",
      "Epoch 29/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4502 - val_loss: 0.7112\n",
      "Epoch 30/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4470 - val_loss: 0.7068\n",
      "Epoch 31/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4451 - val_loss: 0.7046\n",
      "Epoch 32/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4463 - val_loss: 0.7095\n",
      "Epoch 33/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4434 - val_loss: 0.7041\n",
      "Epoch 34/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4428 - val_loss: 0.7033\n",
      "Epoch 35/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4403 - val_loss: 0.6921\n",
      "Epoch 36/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.6885\n",
      "Epoch 37/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4373 - val_loss: 0.6960\n",
      "Epoch 38/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.6902\n",
      "Epoch 39/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4359 - val_loss: 0.6853\n",
      "Epoch 40/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4326 - val_loss: 0.6858\n",
      "Epoch 41/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4337 - val_loss: 0.6797\n",
      "Epoch 42/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4297 - val_loss: 0.6841\n",
      "Epoch 43/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4328 - val_loss: 0.6775\n",
      "Epoch 44/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4271 - val_loss: 0.6849\n",
      "Epoch 45/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4322 - val_loss: 0.6791\n",
      "Epoch 46/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 0.6804\n",
      "Epoch 47/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4236 - val_loss: 0.6657\n",
      "Epoch 48/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4251 - val_loss: 0.6674\n",
      "Epoch 49/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4205 - val_loss: 0.6686\n",
      "Epoch 50/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4234 - val_loss: 0.6622\n",
      "Epoch 51/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4199 - val_loss: 0.6598\n",
      "Epoch 52/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4188 - val_loss: 0.6608\n",
      "Epoch 53/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.6526\n",
      "Epoch 54/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.6543\n",
      "Epoch 55/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 0.6503\n",
      "Epoch 56/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4150 - val_loss: 0.6514\n",
      "Epoch 57/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4126 - val_loss: 0.6473\n",
      "Epoch 58/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.6501\n",
      "Epoch 59/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4101 - val_loss: 0.6507\n",
      "Epoch 60/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 0.6407\n",
      "Epoch 61/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 0.6383\n",
      "Epoch 62/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4048 - val_loss: 0.6411\n",
      "Epoch 63/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4060 - val_loss: 0.6322\n",
      "Epoch 64/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4017 - val_loss: 0.6304\n",
      "Epoch 65/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4035 - val_loss: 0.6300\n",
      "Epoch 66/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4020 - val_loss: 0.6241\n",
      "Epoch 67/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3983 - val_loss: 0.6272\n",
      "Epoch 68/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3981 - val_loss: 0.6245\n",
      "Epoch 69/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.6227\n",
      "Epoch 70/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3954 - val_loss: 0.6229\n",
      "Epoch 71/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 0.6155\n",
      "Epoch 72/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3898 - val_loss: 0.6152\n",
      "Epoch 73/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3882 - val_loss: 0.6114\n",
      "Epoch 74/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3870 - val_loss: 0.6070\n",
      "Epoch 75/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.6051\n",
      "Epoch 76/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.6098\n",
      "Epoch 77/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.5980\n",
      "Epoch 78/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.5953\n",
      "Epoch 79/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.5922\n",
      "Epoch 80/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3811 - val_loss: 0.5933\n",
      "Epoch 81/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.5841\n",
      "Epoch 82/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.5881\n",
      "Epoch 83/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.5814\n",
      "Epoch 84/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.5806\n",
      "Epoch 85/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.5759\n",
      "Epoch 86/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3625 - val_loss: 0.5705\n",
      "Epoch 87/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3626 - val_loss: 0.5670\n",
      "Epoch 88/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3611 - val_loss: 0.5632\n",
      "Epoch 89/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.5599\n",
      "Epoch 90/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3572 - val_loss: 0.5572\n",
      "Epoch 91/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3536 - val_loss: 0.5671\n",
      "Epoch 92/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.5515\n",
      "Epoch 93/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3508 - val_loss: 0.5463\n",
      "Epoch 94/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3490 - val_loss: 0.5474\n",
      "Epoch 95/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.5463\n",
      "Epoch 96/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3451 - val_loss: 0.5427\n",
      "Epoch 97/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3442 - val_loss: 0.5371\n",
      "Epoch 98/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3435 - val_loss: 0.5292\n",
      "Epoch 99/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3397 - val_loss: 0.5340\n",
      "Epoch 100/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3391 - val_loss: 0.5299\n",
      "Epoch 101/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3424 - val_loss: 0.5279\n",
      "Epoch 102/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3360 - val_loss: 0.5187\n",
      "Epoch 103/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.5175\n",
      "Epoch 104/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3327 - val_loss: 0.5137\n",
      "Epoch 105/300\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3292 - val_loss: 0.5162\n",
      "Epoch 106/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3288 - val_loss: 0.5089\n",
      "Epoch 107/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3254 - val_loss: 0.5074\n",
      "Epoch 108/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3226 - val_loss: 0.5075\n",
      "Epoch 109/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3239 - val_loss: 0.5024\n",
      "Epoch 110/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3189 - val_loss: 0.5003\n",
      "Epoch 111/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3165 - val_loss: 0.4964\n",
      "Epoch 112/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3153 - val_loss: 0.4925\n",
      "Epoch 113/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3134 - val_loss: 0.4881\n",
      "Epoch 114/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3109 - val_loss: 0.4873\n",
      "Epoch 115/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3103 - val_loss: 0.4842\n",
      "Epoch 116/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3105 - val_loss: 0.4797\n",
      "Epoch 117/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3056 - val_loss: 0.4767\n",
      "Epoch 118/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3034 - val_loss: 0.4742\n",
      "Epoch 119/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3016 - val_loss: 0.4675\n",
      "Epoch 120/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2978 - val_loss: 0.4657\n",
      "Epoch 121/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2967 - val_loss: 0.4635\n",
      "Epoch 122/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2940 - val_loss: 0.4624\n",
      "Epoch 123/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2939 - val_loss: 0.4559\n",
      "Epoch 124/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2894 - val_loss: 0.4512\n",
      "Epoch 125/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2870 - val_loss: 0.4470\n",
      "Epoch 126/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2847 - val_loss: 0.4412\n",
      "Epoch 127/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2832 - val_loss: 0.4408\n",
      "Epoch 128/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2789 - val_loss: 0.4327\n",
      "Epoch 129/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2748 - val_loss: 0.4343\n",
      "Epoch 130/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2756 - val_loss: 0.4237\n",
      "Epoch 131/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2700 - val_loss: 0.4207\n",
      "Epoch 132/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2665 - val_loss: 0.4174\n",
      "Epoch 133/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2648 - val_loss: 0.4148\n",
      "Epoch 134/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2640 - val_loss: 0.4111\n",
      "Epoch 135/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2587 - val_loss: 0.4007\n",
      "Epoch 136/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2604 - val_loss: 0.3999\n",
      "Epoch 137/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2525 - val_loss: 0.3955\n",
      "Epoch 138/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2529 - val_loss: 0.3936\n",
      "Epoch 139/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2486 - val_loss: 0.3831\n",
      "Epoch 140/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2449 - val_loss: 0.3810\n",
      "Epoch 141/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2417 - val_loss: 0.3693\n",
      "Epoch 142/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2389 - val_loss: 0.3661\n",
      "Epoch 143/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2355 - val_loss: 0.3622\n",
      "Epoch 144/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2313 - val_loss: 0.3581\n",
      "Epoch 145/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2271 - val_loss: 0.3521\n",
      "Epoch 146/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2246 - val_loss: 0.3485\n",
      "Epoch 147/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2212 - val_loss: 0.3401\n",
      "Epoch 148/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2174 - val_loss: 0.3368\n",
      "Epoch 149/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2135 - val_loss: 0.3325\n",
      "Epoch 150/300\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2156 - val_loss: 0.3350\n",
      "Epoch 151/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2129 - val_loss: 0.3224\n",
      "Epoch 152/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2051 - val_loss: 0.3170\n",
      "Epoch 153/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2007 - val_loss: 0.3122\n",
      "Epoch 154/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1995 - val_loss: 0.3245\n",
      "Epoch 155/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1943 - val_loss: 0.2992\n",
      "Epoch 156/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1915 - val_loss: 0.2981\n",
      "Epoch 157/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1872 - val_loss: 0.2913\n",
      "Epoch 158/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1849 - val_loss: 0.2839\n",
      "Epoch 159/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1790 - val_loss: 0.2795\n",
      "Epoch 160/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1768 - val_loss: 0.2739\n",
      "Epoch 161/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1738 - val_loss: 0.2724\n",
      "Epoch 162/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1704 - val_loss: 0.2678\n",
      "Epoch 163/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1668 - val_loss: 0.2596\n",
      "Epoch 164/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1649 - val_loss: 0.2549\n",
      "Epoch 165/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1602 - val_loss: 0.2495\n",
      "Epoch 166/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1580 - val_loss: 0.2466\n",
      "Epoch 167/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.2378\n",
      "Epoch 168/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.2418\n",
      "Epoch 169/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1478 - val_loss: 0.2308\n",
      "Epoch 170/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1427 - val_loss: 0.2253\n",
      "Epoch 171/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1405 - val_loss: 0.2189\n",
      "Epoch 172/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 0.2144\n",
      "Epoch 173/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1352 - val_loss: 0.2073\n",
      "Epoch 174/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1306 - val_loss: 0.2045\n",
      "Epoch 175/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1275 - val_loss: 0.1991\n",
      "Epoch 176/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1258 - val_loss: 0.1948\n",
      "Epoch 177/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1222 - val_loss: 0.1944\n",
      "Epoch 178/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1198 - val_loss: 0.1864\n",
      "Epoch 179/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.1815\n",
      "Epoch 180/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1137 - val_loss: 0.1757\n",
      "Epoch 181/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1115 - val_loss: 0.1724\n",
      "Epoch 182/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1683\n",
      "Epoch 183/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1058 - val_loss: 0.1645\n",
      "Epoch 184/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.1634\n",
      "Epoch 185/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.1560\n",
      "Epoch 186/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0986 - val_loss: 0.1519\n",
      "Epoch 187/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.1504\n",
      "Epoch 188/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0938 - val_loss: 0.1457\n",
      "Epoch 189/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0906 - val_loss: 0.1403\n",
      "Epoch 190/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.1415\n",
      "Epoch 191/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.1330\n",
      "Epoch 192/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0842 - val_loss: 0.1323\n",
      "Epoch 193/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.1292\n",
      "Epoch 194/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.1262\n",
      "Epoch 195/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.1210\n",
      "Epoch 196/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.1162\n",
      "Epoch 197/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.1127\n",
      "Epoch 198/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.1129\n",
      "Epoch 199/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.1077\n",
      "Epoch 200/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.1059\n",
      "Epoch 201/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.1025\n",
      "Epoch 202/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0997\n",
      "Epoch 203/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.0982\n",
      "Epoch 204/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0952\n",
      "Epoch 205/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0929\n",
      "Epoch 206/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0905\n",
      "Epoch 207/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0881\n",
      "Epoch 208/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0857\n",
      "Epoch 209/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0902\n",
      "Epoch 210/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0858\n",
      "Epoch 211/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0824\n",
      "Epoch 212/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0800\n",
      "Epoch 213/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0801\n",
      "Epoch 214/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0775\n",
      "Epoch 215/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0774\n",
      "Epoch 216/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0716\n",
      "Epoch 217/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0724\n",
      "Epoch 218/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0698\n",
      "Epoch 219/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0676\n",
      "Epoch 220/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0690\n",
      "Epoch 221/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0650\n",
      "Epoch 222/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0657\n",
      "Epoch 223/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0626\n",
      "Epoch 224/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0618\n",
      "Epoch 225/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0607\n",
      "Epoch 226/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0595\n",
      "Epoch 227/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0604\n",
      "Epoch 228/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0576\n",
      "Epoch 229/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.0606\n",
      "Epoch 230/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0420 - val_loss: 0.0559\n",
      "Epoch 231/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.0572\n",
      "Epoch 232/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0553\n",
      "Epoch 233/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0540\n",
      "Epoch 234/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0536\n",
      "Epoch 235/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0541\n",
      "Epoch 236/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0386 - val_loss: 0.0535\n",
      "Epoch 237/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0502\n",
      "Epoch 238/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0502\n",
      "Epoch 239/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.0510\n",
      "Epoch 240/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0502\n",
      "Epoch 241/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0488\n",
      "Epoch 242/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0356 - val_loss: 0.0477\n",
      "Epoch 243/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0499\n",
      "Epoch 244/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0477\n",
      "Epoch 245/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0355 - val_loss: 0.0458\n",
      "Epoch 246/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0441\n",
      "Epoch 247/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0450\n",
      "Epoch 248/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0345 - val_loss: 0.0443\n",
      "Epoch 249/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.0441\n",
      "Epoch 250/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.0463\n",
      "Epoch 251/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0423\n",
      "Epoch 252/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0434\n",
      "Epoch 253/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.0416\n",
      "Epoch 254/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0437\n",
      "Epoch 255/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0463\n",
      "Epoch 256/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.0432\n",
      "Epoch 257/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0401\n",
      "Epoch 258/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.0411\n",
      "Epoch 259/300\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0399\n",
      "Epoch 260/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0393\n",
      "Epoch 261/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.0393\n",
      "Epoch 262/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0398\n",
      "Epoch 263/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.0411\n",
      "Epoch 264/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0373\n",
      "Epoch 265/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.0379\n",
      "Epoch 266/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0319 - val_loss: 0.0402\n",
      "Epoch 267/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.0373\n",
      "Epoch 268/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.0386\n",
      "Epoch 269/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0358\n",
      "Epoch 270/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0387\n",
      "Epoch 271/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.0406\n",
      "Epoch 272/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0405\n",
      "Epoch 273/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.0406\n",
      "Epoch 274/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0357\n",
      "Epoch 275/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0347\n",
      "Epoch 276/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0350\n",
      "Epoch 277/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0349\n",
      "Epoch 278/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0352\n",
      "Epoch 279/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0356\n",
      "Epoch 280/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.0335\n",
      "Epoch 281/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0417\n",
      "Epoch 282/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.0364\n",
      "Epoch 283/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0332\n",
      "Epoch 284/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0336\n",
      "Epoch 285/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0351\n",
      "Epoch 286/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0351\n",
      "Epoch 287/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0333\n",
      "Epoch 288/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0341\n",
      "Epoch 289/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0322\n",
      "Epoch 290/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0322\n",
      "Epoch 291/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0329\n",
      "Epoch 292/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0323\n",
      "Epoch 293/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0331\n",
      "Epoch 294/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0324\n",
      "Epoch 295/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0318\n",
      "Epoch 296/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0331\n",
      "Epoch 297/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0324\n",
      "Epoch 298/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0339\n",
      "Epoch 299/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0319\n",
      "Epoch 300/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0335\n"
     ]
    }
   ],
   "source": [
    "model_adam = NeuralNet()\n",
    "model_adam.fit(dataset.X, dataset.y, [layer_width], epochs=epochs, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Runtime measurement of Weight Norm Preservation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T12:14:55.981823700Z",
     "start_time": "2023-10-02T12:14:48.649856500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer1 sampling: 100%|██████████| 100/100 [00:01<00:00, 78.71it/s]\n",
      "Layer1 sampling: 100%|██████████| 100/100 [00:02<00:00, 48.45it/s]\n",
      "Layer1 sampling: 100%|██████████| 100/100 [00:01<00:00, 77.04it/s]\n",
      "Layer1 sampling: 100%|██████████| 100/100 [00:01<00:00, 78.66it/s]\n",
      "Layer1 sampling: 100%|██████████| 100/100 [00:01<00:00, 72.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 1.465421220008284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_base = model_adam\n",
    "\n",
    "y_nn_train = model_base.predict(dataset.X)\n",
    "\n",
    "model_sampled = SampledNet()\n",
    "wrapped = wrapper(model_sampled.fit, dataset.X, model_base, layer2=\"bias_only\", r=0.04,\n",
    "                  project_onto_boundary=False, choose_x_2=\"norm\")\n",
    "print(\"Runtime: \" + str(timeit.timeit(wrapped, number=5) / 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Runtime measurement of Pair Selection with Proximity Optimization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer1 sampling: 100%|██████████| 100/100 [00:00<00:00, 164.01it/s]\n",
      "Layer1 sampling: 100%|██████████| 100/100 [00:00<00:00, 171.99it/s]\n",
      "Layer1 sampling: 100%|██████████| 100/100 [00:00<00:00, 172.96it/s]\n",
      "Layer1 sampling: 100%|██████████| 100/100 [00:00<00:00, 168.18it/s]\n",
      "Layer1 sampling: 100%|██████████| 100/100 [00:00<00:00, 168.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.6027322999900206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_sampled_opt = SampledNet()\n",
    "wrapped = wrapper(model_sampled_opt.fit, dataset.X, model_base, layer2=\"bias_only\", r=0.04,\n",
    "                  project_onto_boundary=False, choose_x_2=\"norm_kdtree\")\n",
    "print(\"Runtime: \" + str(timeit.timeit(wrapped, number=5) / 5))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:14:59.002357300Z",
     "start_time": "2023-10-02T12:14:55.987238400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
