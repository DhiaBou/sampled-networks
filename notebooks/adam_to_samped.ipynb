{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from models.neural_net import NeuralNet\n",
    "from view.visualizer import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = 3  # Input space dimensions\n",
    "yd = 4  # Output dimension\n",
    "num_samples = 50  # Number of data points\n",
    "epochs = 100  # Number of training epochs\n",
    "l = [10]  # Number of neurons in each layer\n",
    "\n",
    "dataset = Dataset()\n",
    "dataset.create_dataset_sinus_2d(num_samples)\n",
    "dataset.scale(preprocessing.MinMaxScaler(feature_range=(0, 2)))\n",
    "dataset.split_train_test(0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network training with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = NeuralNet()\n",
    "model_nn.fit(dataset.X_train, dataset.y_train, l, validation_split=0.2, epochs=1)\n",
    "y_nn_train = model_nn.predict(dataset.X_train)\n",
    "y_nn_test = model_nn.predict(dataset.X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampled Netwrok training.\n",
    "### very first algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sampled = SampledNet()\n",
    "x_1_X2_tuples = model_sampled.fit(dataset.X_train, y_nn_train, model_nn, layer2=\"classic\", choose_x_2=\"angle\")\n",
    "\n",
    "model_nn_vs_model_sampled(dataset, model_nn, model_sampled, x_1_X2_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### add radius: an interval for the distance to the bias origin, and choose x_2, so that \\hat{w_i} has the closest norm to w_i"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_sampled = SampledNet()\n",
    "x_1_X2_tuples = model_sampled.fit(dataset.X_train, y_nn_train, model_nn, layer2=\"classic\", radius=0,\n",
    "                                  choose_x_2=\"norm\")\n",
    "model_nn_vs_model_sampled(dataset, model_nn, model_sampled, x_1_X2_tuples)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### shift x_1 and x_2 so that x_1 lies on the original bias origin"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_sampled = SampledNet()\n",
    "x_1_X2_tuples = model_sampled.fit(dataset.X_train, y_nn_train, model_nn, layer2=\"classic\", radius=0.09,\n",
    "                                  choose_x_2=\"norm\", project_onto_boundary=True)\n",
    "\n",
    "model_nn_vs_model_sampled(dataset, model_nn, model_sampled, x_1_X2_tuples)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### use ridge regression for layer 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_sampled = SampledNet()\n",
    "model_sampled.fit(dataset.X_train, y_nn_train, model_nn, layer2=\"ridge\", radius=0.05,\n",
    "                  choose_x_2=\"norm\")\n",
    "\n",
    "model_nn_vs_model_sampled(dataset, model_nn, model_sampled, x_1_X2_tuples)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate radius vs loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_nn_train = model_nn.predict(dataset.X_train)\n",
    "y_nn_test = model_nn.predict(dataset.X_test)\n",
    "weight1 = []\n",
    "weight2 = []\n",
    "losses = []\n",
    "radii = np.linspace(0, 0.5, 10)\n",
    "for radius in radii:\n",
    "    model_sampled = SampledNet()\n",
    "    model_sampled.fit(\n",
    "        dataset.X_train, y_nn_train, model_nn, layer2=\"classic\", radius=radius, alpha=-1, verbose=0\n",
    "    )\n",
    "    weight1.append(model_sampled.weights[0])\n",
    "    weight2.append(model_nn.weights[0])\n",
    "    y_sampled_test = model_sampled.predict(dataset.X_test)\n",
    "    loss_sampled_nn = loss_mse(y_sampled_test, y_nn_test)\n",
    "    losses.append(loss_sampled_nn)\n",
    "    print(loss_sampled_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vector_differences(weight1, weight2, radii, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### augment data with gaussian sampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xd = 3  # Input space dimensions\n",
    "yd = 4  # Output dimension\n",
    "num_samples = 50  # Number of data points\n",
    "epochs = 100  # Number of training epochs\n",
    "l = [100]  # Number of neurons in each layer\n",
    "\n",
    "dataset = Dataset()\n",
    "dataset.create_dataset_sinus_2d(num_samples)\n",
    "dataset.scale(preprocessing.MinMaxScaler(feature_range=(-2, 2)))\n",
    "dataset.split_train_test(0.2)\n",
    "\n",
    "model_nn = NeuralNet()\n",
    "model_nn.fit(dataset.X_train, dataset.y_train, l, validation_split=0.2, epochs=1)\n",
    "y_nn_train = model_nn.predict(dataset.X_train)\n",
    "y_nn_test = model_nn.predict(dataset.X_test)\n",
    "\n",
    "model_sampled = SampledNet()\n",
    "x_1_X2_tuples = model_sampled.fit(dataset.X_train, y_nn_train, model_nn, layer2=\"classic\", radius=0.05,\n",
    "                                  choose_x_2=\"norm\")\n",
    "\n",
    "model_sampled_input_augmented = SampledNet()\n",
    "x_1_X2_tuples_input_augmented = model_sampled_input_augmented.fit(dataset.X_train, y_nn_train, model_nn,\n",
    "                                                                  layer2=\"classic\",\n",
    "                                                                  radius=0.05,\n",
    "                                                                  choose_x_2=\"norm\", augment_data=(1, 10))\n",
    "\n",
    "model_nn_vs_model_sampled(dataset, model_nn, model_sampled, x_1_X2_tuples)\n",
    "model_nn_vs_model_sampled(dataset, model_nn, model_sampled_input_augmented, x_1_X2_tuples_input_augmented)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
